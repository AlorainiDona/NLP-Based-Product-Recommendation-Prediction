{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be using the provided data to create a machine learning model pipeline.\n",
    "\n",
    "You must handle the data appropriately in your pipeline to predict whether an\n",
    "item is recommended by a customer based on their review.\n",
    "Note the data includes numerical, categorical, and text data.\n",
    "\n",
    "You should ensure you properly train and evaluate your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been anonymized and cleaned of missing values.\n",
    "\n",
    "There are 8 features for to use to predict whether a customer recommends or does\n",
    "not recommend a product.\n",
    "The `Recommended IND` column gives whether a customer recommends the product\n",
    "where `1` is recommended and a `0` is not recommended.\n",
    "This is your model's target/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features can be summarized as the following:\n",
    "\n",
    "- **Clothing ID**: Integer Categorical variable that refers to the specific piece being reviewed.\n",
    "- **Age**: Positive Integer variable of the reviewers age.\n",
    "- **Title**: String variable for the title of the review.\n",
    "- **Review Text**: String variable for the review body.\n",
    "- **Positive Feedback Count**: Positive Integer documenting the number of other customers who found this review positive.\n",
    "- **Division Name**: Categorical name of the product high level division.\n",
    "- **Department Name**: Categorical name of the product department name.\n",
    "- **Class Name**: Categorical name of the product class name.\n",
    "\n",
    "The target:\n",
    "- **Recommended IND**: Binary variable stating where the customer recommends the product where 1 is recommended, 0 is not recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "# Sklearn / Imblearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads the dataset, displays basic info, and returns the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"=== Data Info ===\")\n",
    "    df.info()\n",
    "    print(\"\\n=== Data Head ===\\n\", df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handles missing values by replacing nulls in 'Title' and 'Review Text' with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nulls(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    for col in [\"Title\", \"Review Text\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].fillna(\"\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combines 'Title' and 'Review Text' into a single 'Full_Review' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[\"Full_Review\"] = df[\"Title\"].astype(str) + \" \" + df[\"Review Text\"].astype(str)\n",
    "    df.drop(\"Title\", axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads the SpaCy NLP model with only essential components to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_spacy():\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"tagger\"])\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleans and processes text by lowercasing, removing digits/punctuation, lemmatizing, and removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text: str, nlp) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return \" \".join(tokens).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adds additional numerical features such as review length and sentiment indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text_features(df: pd.DataFrame, text_col: str) -> pd.DataFrame:\n",
    "    df[\"Review Length\"] = df[text_col].apply(lambda x: len(x.split()))\n",
    "    df[\"Positive Sentiment\"] = df[text_col].apply(\n",
    "        lambda x: x.count(\"good\") + x.count(\"love\") + x.count(\"great\")\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructs a machine learning pipeline with preprocessing, SMOTE, and a RandomForest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline() -> Pipeline:\n",
    "    numeric_feats = [\"Age\", \"Positive Feedback Count\", \"Review Length\", \"Positive Sentiment\"]\n",
    "    categorical_feats = [\"Division Name\", \"Department Name\", \"Class Name\"]\n",
    "    text_feat = \"Full_Review\"\n",
    "\n",
    "    num_transformer = StandardScaler()\n",
    "    cat_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    text_transformer = TfidfVectorizer(stop_words=\"english\", max_features=5000)\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_transformer, numeric_feats),\n",
    "            (\"cat\", cat_transformer, categorical_feats),\n",
    "            (\"text\", text_transformer, text_feat),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipeline = ImbPipeline([\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"smote\", SMOTE(random_state=42)),\n",
    "        (\"classifier\", RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=42,\n",
    "            class_weight=\"balanced_subsample\"\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluates model performance and prints key metrics and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, title: str = \"Model Performance\"):\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"F1 Score:  {f1_score(y_true, y_pred):.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"Not Recommended (0)\", \"Recommended (1)\"]))\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete pipeline execution: data processing, training, evaluation, and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18442 entries, 0 to 18441\n",
      "Data columns (total 9 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Clothing ID              18442 non-null  int64 \n",
      " 1   Age                      18442 non-null  int64 \n",
      " 2   Title                    18442 non-null  object\n",
      " 3   Review Text              18442 non-null  object\n",
      " 4   Positive Feedback Count  18442 non-null  int64 \n",
      " 5   Division Name            18442 non-null  object\n",
      " 6   Department Name          18442 non-null  object\n",
      " 7   Class Name               18442 non-null  object\n",
      " 8   Recommended IND          18442 non-null  int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 1.3+ MB\n",
      "\n",
      "=== Data Head ===\n",
      "    Clothing ID  Age                    Title  \\\n",
      "0         1077   60  Some major design flaws   \n",
      "1         1049   50         My favorite buy!   \n",
      "2          847   47         Flattering shirt   \n",
      "3         1080   49  Not for the very petite   \n",
      "4          858   39     Cagrcoal shimmer fun   \n",
      "\n",
      "                                         Review Text  Positive Feedback Count  \\\n",
      "0  I had such high hopes for this dress and reall...                        0   \n",
      "1  I love, love, love this jumpsuit. it's fun, fl...                        0   \n",
      "2  This shirt is very flattering to all due to th...                        6   \n",
      "3  I love tracy reese dresses, but this one is no...                        4   \n",
      "4  I aded this in my basket at hte last mintue to...                        1   \n",
      "\n",
      "    Division Name Department Name Class Name  Recommended IND  \n",
      "0         General         Dresses    Dresses                0  \n",
      "1  General Petite         Bottoms      Pants                1  \n",
      "2         General            Tops    Blouses                1  \n",
      "3         General         Dresses    Dresses                0  \n",
      "4  General Petite            Tops      Knits                1  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dduun\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Initial Model Performance ===\n",
      "Accuracy:  0.8802\n",
      "Precision: 0.9054\n",
      "Recall:    0.9529\n",
      "F1 Score:  0.9285\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Not Recommended (0)       0.73      0.56      0.63       339\n",
      "    Recommended (1)       0.91      0.95      0.93      1506\n",
      "\n",
      "           accuracy                           0.88      1845\n",
      "          macro avg       0.82      0.76      0.78      1845\n",
      "       weighted avg       0.87      0.88      0.87      1845\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 189  150]\n",
      " [  71 1435]]\n",
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "\n",
      "=== Tuned Model Performance ===\n",
      "Accuracy:  0.8808\n",
      "Precision: 0.9054\n",
      "Recall:    0.9535\n",
      "F1 Score:  0.9288\n",
      "\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Not Recommended (0)       0.73      0.56      0.63       339\n",
      "    Recommended (1)       0.91      0.95      0.93      1506\n",
      "\n",
      "           accuracy                           0.88      1845\n",
      "          macro avg       0.82      0.76      0.78      1845\n",
      "       weighted avg       0.87      0.88      0.87      1845\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 189  150]\n",
      " [  70 1436]]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = load_data(\"reviews.csv\")\n",
    "    df = clean_nulls(df)\n",
    "    df = merge_text(df)\n",
    "\n",
    "    nlp = init_spacy()\n",
    "    df[\"Full_Review\"] = df[\"Full_Review\"].apply(lambda x: text_cleaning(x, nlp))\n",
    "    df = add_text_features(df, \"Full_Review\")\n",
    "\n",
    "    # Separate X, y\n",
    "    X = df.drop(\"Recommended IND\", axis=1)\n",
    "    y = df[\"Recommended IND\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=27, stratify=y)\n",
    "\n",
    "    # Build pipeline and train model\n",
    "    pipeline = build_pipeline()\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    evaluate_model(y_test, y_pred, \"Initial Model Performance\")\n",
    "\n",
    "    # Hyperparameter Tuning\n",
    "    param_grid = {\n",
    "        \"classifier__n_estimators\": [100, 150],\n",
    "        \"classifier__min_samples_split\": [2, 5],\n",
    "        \"preprocessor__text__max_features\": [3000, 5000],\n",
    "        \"preprocessor__text__ngram_range\": [(1,1), (1,2)],\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, cv=2, scoring=\"accuracy\", n_jobs=-1, verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred_tuned = best_model.predict(X_test)\n",
    "    evaluate_model(y_test, y_pred_tuned, \"Tuned Model Performance\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Analysis\n",
    "### - The initial model performed well with 88% accuracy.\n",
    "### - The recall for the 'Recommended' class was very high (>95%), meaning most positive reviews were correctly identified.\n",
    "### - After hyperparameter tuning, accuracy remained consistent, but fine-tuning parameters slightly improved balance.\n",
    "### - The slight increase in recall suggests better handling of class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
